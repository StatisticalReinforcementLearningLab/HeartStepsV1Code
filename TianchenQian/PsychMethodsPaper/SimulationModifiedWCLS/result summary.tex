%% LyX 2.2.3 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\documentclass[english]{article}
\usepackage[T1]{fontenc}
\usepackage[latin9]{inputenc}
\usepackage{geometry}
\geometry{verbose,tmargin=3cm,bmargin=3cm,lmargin=3cm,rmargin=3cm}
\usepackage{array}
\usepackage{multirow}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{setspace}
\onehalfspacing

\makeatletter

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% LyX specific LaTeX commands.
%% Because html converters don't know tabularnewline
\providecommand{\tabularnewline}{\\}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Textclass specific LaTeX commands.
\theoremstyle{plain}
\newtheorem{thm}{\protect\theoremname}

\makeatother

\usepackage{babel}
\providecommand{\theoremname}{Theorem}

\begin{document}

\title{Summary of the simulation result for improving efficiency of WCLS}

\author{Tianchen Qian}

\date{2018.07.17}
\maketitle

\section{Estimator}

Consider four estimators: WCLS, WCLS with $\tilde{p}_{t}S_{t}$ included
in $g(H_{t})$, WCLS with $A_{t}$ not centered in the residual part,
and WCLS with $A_{t}$ not centered in the residual part and a special
weight

WCLS-1: WCLS is the solution to the following estimating equation:
\[
\sum_{i=1}^{n}\sum_{t=1}^{T}\{Y_{t+1}-g(H_{t})^{T}\alpha-(A_{t}-\tilde{p}_{t})S_{t}^{T}\beta\}W_{t}\begin{bmatrix}g(H_{t})\\
(A_{t}-\tilde{p}_{t})S_{t}
\end{bmatrix}.
\]

WCLS-2: WCLS with $\tilde{p}_{t}S_{t}$ included in $g(H_{t})$ is
self-explanatory.

WCLS-3: WCLS with $A_{t}$ not centered in the residual part is the
solution to the following estimating equation:

\[
\sum_{i=1}^{n}\sum_{t=1}^{T}\{Y_{t+1}-g(H_{t})^{T}\alpha-A_{t}S_{t}^{T}\beta\}W_{t}\begin{bmatrix}g(H_{t})\\
(A_{t}-\tilde{p}_{t})S_{t}
\end{bmatrix}.
\]

WCLS-4: WCLS with $A_{t}$ not centered in the residual part is the
solution to the following estimating equation:

\[
\sum_{i=1}^{n}\sum_{t=1}^{T}\{Y_{t+1}-g(H_{t})^{T}\alpha-A_{t}S_{t}^{T}\beta\}W_{t}\frac{1}{\tilde{p}_{t}(1-\tilde{p}_{t})}\begin{bmatrix}g(H_{t})\\
(A_{t}-\tilde{p}_{t})S_{t}
\end{bmatrix}.
\]

WCLS-5: WCLS with $p_{t}S_{t}$ included in $g(H_{t})$ is self-explanatory.
(Peng suggests this.)

Here, the weight variable $W_{t}$ equals
\[
W_{t}=\left(\frac{\tilde{p}_{t}}{p_{t}}\right)^{A_{t}}\left(\frac{1-\tilde{p}_{t}}{1-p_{t}}\right)^{1-A_{t}}.
\]
\begin{thm}
If our working model (the $g$ part) accidentally is correct and our
treatment model is correct conditional on entire history and residual
variance is constant, (which implies that we can set $\tilde{p}_{t}=p_{t}$
and $W_{t}=1$), then WCLS-3 is semiparametric efficient.
\end{thm}

\begin{proof}
See the note ``note\_20180730 - EIF alternative form (action centering)
for continuous and binary outcomes.pdf'' (copied from the folder
of binary outcome project).
\end{proof}
%
Conjecture: WCLS-2 has similar performance to WCLS-3 when $S_{t}$
is low-dimensional compared to $n$ so that including $\tilde{p}_{t}S_{t}$
in $g(H_{t})$ does not result in a big loss of degrees of freedom.

Note: Susan says that WCLS-4 is efficient in the above theorem situation
instead of WCLS-3. I don't think so.

\section{Simulation}

\subsection{Generative model}
\begin{itemize}
\item Covariate $Z_{t}$ is an exogenous AR(1) process with auto-correlation
0.5.
\item The randomization probability is $p_{t}(H_{t})=\min[0.8,\max\{0.2,\text{expit}(0.5Z_{t})\}]$.
\item The outcome $Y_{t+1}$ is generated as Gaussian with mean $\alpha_{0}+\alpha_{1}Z_{t}+A_{t}(\beta_{0}+\beta_{1}Z_{t})$
and variance 1.
\item The parameter value is $\beta_{0}=0.5$, $\beta_{1}=1$, $\alpha_{0}=-1$,
$\alpha_{1}=1$.
\end{itemize}

\subsection{Simulation result}

We correctly specify all the models for all estimators (so that $Z_{t}$
is included in both the control part and the treatment effect part,
and we set $\tilde{p}_{t}=p_{t}(H_{t})$).

Result is in Table 1. Observations:
\begin{itemize}
\item All three estimators have close to 0 bias. (And by theory we know
they are all consistent.)
\item WCLS-2 and WCLS-3 have almost the same SD, whereas WCLS-1 is less
efficient than the other two in estimating $\beta_{1}$.
\item WCLS-4 is slightly less efficient than WCLS-3 and WCLS-2, but more
efficient than WCLS-1.
\end{itemize}
\begin{table}[h]
\caption{Consistency and relative efficiency among the three estimators, based
on 10,000 simulations}
\begin{centering}
\begin{tabular}{cccccc}
\hline 
 &  & \multicolumn{2}{c}{$\beta_{0}$} & \multicolumn{2}{c}{$\beta_{1}$}\tabularnewline
\cline{3-6} 
 &  & Bias & SD & Bias & SD\tabularnewline
\hline 
\multirow{4}{*}{$n=100,T=30$} & WCLS-1 & $3.8\times10^{-4}$ & 0.0386 & $1.7\times10^{-4}$ & 0.0376\tabularnewline
 & WCLS-2 & $2.5\times10^{-4}$ & 0.0380 & $-1.9\times10^{-4}$ & 0.0354\tabularnewline
 & WCLS-3 & $2.5\times10^{-4}$ & 0.0380 & $-1.8\times10^{-4}$ & 0.0354\tabularnewline
 & WCLS-4 & $2.5\times10^{-4}$ & 0.381 & $-1.6\times10^{-4}$ & 0.0356\tabularnewline
\hline 
\multirow{4}{*}{$n=30,T=210$} & WCLS-1 & $8.7\times10^{-4}$ & 0.0259 & $6.3\times10^{-4}$ & 0.0260\tabularnewline
 & WCLS-2 & $7.9\times10^{-4}$ & 0.0258 & $4.5\times10^{-4}$ & 0.0242\tabularnewline
 & WCLS-3 & $7.9\times10^{-4}$ & 0.0258 & $5.0\times10^{-4}$ & 0.0241\tabularnewline
 & WCLS-4 &  &  &  & \tabularnewline
\hline 
\end{tabular}
\par\end{centering}
\end{table}

\end{document}
